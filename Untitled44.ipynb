{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install -q google-colab-selenium\n",
        "import google_colab_selenium as gs\n",
        "driver = gs.Chrome()\n",
        "driver.get(\"https://www.google.com\")\n",
        "print(\"✅ Test Success: Page title =\", driver.title)\n",
        "driver.quit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "id": "nF8gly21a5u6",
        "outputId": "7d036dc3-249f-4d2b-a7d6-607f73380f76"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.6 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <div class=\"spinner-container\">\n",
              "                <div class=\"spinner\" id=\"5488b38f-6adb-4b13-a907-93c2a6f4f625-circle\"></div>\n",
              "                <div class=\"spinner-text\" id=\"5488b38f-6adb-4b13-a907-93c2a6f4f625-text\">Updating and upgrading APT</div>\n",
              "            </div>\n",
              "            <style>\n",
              "                @keyframes spin {\n",
              "                    from { transform: rotate(0deg); }\n",
              "                    to { transform: rotate(360deg); }\n",
              "                }\n",
              "\n",
              "                .spinner-container {\n",
              "                    display: flex;\n",
              "                    align-items: center;\n",
              "                    margin-bottom: 3px;\n",
              "                }\n",
              "\n",
              "                .spinner {\n",
              "                    border: 3px solid rgba(0, 0, 0, 0.1);\n",
              "                    border-left-color: lightblue;\n",
              "                    border-radius: 50%;\n",
              "                    width: 12px;\n",
              "                    height: 12px;\n",
              "                    animation: spin 1s linear infinite;\n",
              "                }\n",
              "\n",
              "                .spinner-text {\n",
              "                    padding-left: 6px;\n",
              "                }\n",
              "            </style>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            const element = document.getElementById(\"5488b38f-6adb-4b13-a907-93c2a6f4f625-circle\");\n",
              "            element.style.border = \"3px solid limegreen\";\n",
              "            element.style.animation = \"none\";\n",
              "\n",
              "            const text = document.getElementById(\"5488b38f-6adb-4b13-a907-93c2a6f4f625-text\");\n",
              "            text.innerText = \"Updated and upgraded APT\";\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <div class=\"spinner-container\">\n",
              "                <div class=\"spinner\" id=\"c7807389-bbaa-4a21-96e9-c5d5acc82513-circle\"></div>\n",
              "                <div class=\"spinner-text\" id=\"c7807389-bbaa-4a21-96e9-c5d5acc82513-text\">Downloading Google Chrome</div>\n",
              "            </div>\n",
              "            <style>\n",
              "                @keyframes spin {\n",
              "                    from { transform: rotate(0deg); }\n",
              "                    to { transform: rotate(360deg); }\n",
              "                }\n",
              "\n",
              "                .spinner-container {\n",
              "                    display: flex;\n",
              "                    align-items: center;\n",
              "                    margin-bottom: 3px;\n",
              "                }\n",
              "\n",
              "                .spinner {\n",
              "                    border: 3px solid rgba(0, 0, 0, 0.1);\n",
              "                    border-left-color: lightblue;\n",
              "                    border-radius: 50%;\n",
              "                    width: 12px;\n",
              "                    height: 12px;\n",
              "                    animation: spin 1s linear infinite;\n",
              "                }\n",
              "\n",
              "                .spinner-text {\n",
              "                    padding-left: 6px;\n",
              "                }\n",
              "            </style>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            const element = document.getElementById(\"c7807389-bbaa-4a21-96e9-c5d5acc82513-circle\");\n",
              "            element.style.border = \"3px solid limegreen\";\n",
              "            element.style.animation = \"none\";\n",
              "\n",
              "            const text = document.getElementById(\"c7807389-bbaa-4a21-96e9-c5d5acc82513-text\");\n",
              "            text.innerText = \"Downloaded Google Chrome\";\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <div class=\"spinner-container\">\n",
              "                <div class=\"spinner\" id=\"31a7be89-5e5e-4466-8f03-b9bb635a545b-circle\"></div>\n",
              "                <div class=\"spinner-text\" id=\"31a7be89-5e5e-4466-8f03-b9bb635a545b-text\">Initializing Chromedriver</div>\n",
              "            </div>\n",
              "            <style>\n",
              "                @keyframes spin {\n",
              "                    from { transform: rotate(0deg); }\n",
              "                    to { transform: rotate(360deg); }\n",
              "                }\n",
              "\n",
              "                .spinner-container {\n",
              "                    display: flex;\n",
              "                    align-items: center;\n",
              "                    margin-bottom: 3px;\n",
              "                }\n",
              "\n",
              "                .spinner {\n",
              "                    border: 3px solid rgba(0, 0, 0, 0.1);\n",
              "                    border-left-color: lightblue;\n",
              "                    border-radius: 50%;\n",
              "                    width: 12px;\n",
              "                    height: 12px;\n",
              "                    animation: spin 1s linear infinite;\n",
              "                }\n",
              "\n",
              "                .spinner-text {\n",
              "                    padding-left: 6px;\n",
              "                }\n",
              "            </style>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            const element = document.getElementById(\"31a7be89-5e5e-4466-8f03-b9bb635a545b-circle\");\n",
              "            element.style.border = \"3px solid limegreen\";\n",
              "            element.style.animation = \"none\";\n",
              "\n",
              "            const text = document.getElementById(\"31a7be89-5e5e-4466-8f03-b9bb635a545b-text\");\n",
              "            text.innerText = \"Initialized Chromedriver\";\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Test Success: Page title = Google\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Z25DW9OYTTDB",
        "outputId": "28131b6a-d1f8-474b-e4b8-aa69f73d9080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Setting up Delhi Courts Scraper...\n",
            "✅ Setup complete!\n",
            "✅ Libraries imported!\n",
            "✅ Delhi Courts Scraper ready!\n",
            "✅ All functions ready!\n",
            "\n",
            "🚀 Starting Delhi Courts Scraper...\n",
            "\n",
            "\n",
            "======================================================================\n",
            "  Delhi District Courts - Cause List Scraper\n",
            "======================================================================\n",
            "\n",
            "🌐 Starting browser...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <div class=\"spinner-container\">\n",
              "                <div class=\"spinner\" id=\"d2a4f904-0b76-4783-be00-2f238e3ef519-circle\"></div>\n",
              "                <div class=\"spinner-text\" id=\"d2a4f904-0b76-4783-be00-2f238e3ef519-text\">Initializing Chromedriver</div>\n",
              "            </div>\n",
              "            <style>\n",
              "                @keyframes spin {\n",
              "                    from { transform: rotate(0deg); }\n",
              "                    to { transform: rotate(360deg); }\n",
              "                }\n",
              "\n",
              "                .spinner-container {\n",
              "                    display: flex;\n",
              "                    align-items: center;\n",
              "                    margin-bottom: 3px;\n",
              "                }\n",
              "\n",
              "                .spinner {\n",
              "                    border: 3px solid rgba(0, 0, 0, 0.1);\n",
              "                    border-left-color: lightblue;\n",
              "                    border-radius: 50%;\n",
              "                    width: 12px;\n",
              "                    height: 12px;\n",
              "                    animation: spin 1s linear infinite;\n",
              "                }\n",
              "\n",
              "                .spinner-text {\n",
              "                    padding-left: 6px;\n",
              "                }\n",
              "            </style>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            const element = document.getElementById(\"d2a4f904-0b76-4783-be00-2f238e3ef519-circle\");\n",
              "            element.style.border = \"3px solid limegreen\";\n",
              "            element.style.animation = \"none\";\n",
              "\n",
              "            const text = document.getElementById(\"d2a4f904-0b76-4783-be00-2f238e3ef519-text\");\n",
              "            text.innerText = \"Initialized Chromedriver\";\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Browser ready!\n",
            "🏛️ Available Delhi District Courts:\n",
            "\n",
            "  1. Central Delhi\n",
            "  2. East Delhi\n",
            "  3. New Delhi\n",
            "  4. North Delhi\n",
            "  5. North East Delhi\n",
            "  6. North West Delhi\n",
            "  7. Shahdara Delhi\n",
            "  8. South Delhi\n",
            "  9. South East Delhi\n",
            "  10. South West Delhi\n",
            "  11. West Delhi\n",
            "  12. ALL Courts (Download from all)\n",
            "\n",
            "👉 Select court (1-12): 1\n",
            "\n",
            "📅 Enter date (DD-MM-YYYY) [Press Enter for today]: 16-10-2025\n",
            "✅ Date: 16-10-2025\n",
            "\n",
            "\n",
            "======================================================================\n",
            "Downloading: Central Delhi - 16-10-2025\n",
            "======================================================================\n",
            "\n",
            "🔍 Trying: https://delhicourts.nic.in/writereaddata/Upload/CauseList/Central/16102025.pdf\n",
            "🔍 Trying: https://delhicourts.nic.in/writereaddata/Upload/CauseList/Central/16-10-2025.pdf\n",
            "🔍 Trying: https://delhicourts.nic.in/writereaddata/Upload/CauseList/Central/causelist_16102025.pdf\n",
            "🔍 Trying: https://delhicourts.nic.in/writereaddata/Upload/CauseList/Central/CauseList_16102025.pdf\n",
            "🔍 Trying: https://delhicourts.nic.in/writereaddata/Upload/CauseList/Central/16.10.2025.pdf\n",
            "📍 Navigating to https://delhicourts.nic.in/\n",
            "⚠️ Could not find cause list link\n",
            "⚠️ Could not select district\n",
            "⚠️ Could not enter date\n",
            "⚠️ Could not click submit\n",
            "📍 Opening Central Delhi court website...\n",
            "🔍 Searching for cause list links...\n",
            "✅ Found 1 potential cause list links\n",
            "\n",
            "======================================================================\n",
            "✅ Download Complete! Got 0 files\n",
            "======================================================================\n",
            "\n",
            "⚠️ No cause lists were downloaded.\n",
            "\n",
            "Possible reasons:\n",
            "  • Cause lists not yet published for this date (try 16-10-2025)\n",
            "  • Court website structure has changed\n",
            "  • Internet connectivity issues\n",
            "\n",
            "Try:\n",
            "  • A different date (yesterday)\n",
            "  • Checking the court website manually\n",
            "\n",
            "💾 Summary saved: summary_20251016_192458.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/content/delhi_courts_output/json/summary_20251016_192458.json"
            ],
            "text/html": [
              "<a href='/content/delhi_courts_output/json/summary_20251016_192458.json' target='_blank'>/content/delhi_courts_output/json/summary_20251016_192458.json</a><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Browser closed\n",
            "\n",
            "======================================================================\n",
            "✅ Process Complete!\n",
            "======================================================================\n",
            "\n",
            "Files saved to: /content/delhi_courts_output\n",
            "\n",
            "To run again, execute: run_delhi_scraper()\n",
            "For quick download: quick_download_delhi(date='16-10-2025', court='New Delhi')\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ═══════════════════════════════════════════════════════════════════════\n",
        "# Delhi District Courts Cause List Scraper - Google Colab (BEST FIX: google-colab-selenium)\n",
        "# Works with: https://delhicourts.nic.in/\n",
        "# Copy this ENTIRE code into ONE cell and run!\n",
        "# ═══════════════════════════════════════════════════════════════════════\n",
        "\n",
        "# ─── STEP 1: SETUP (Auto-Handles Chrome + Driver) ───\n",
        "print(\"🚀 Setting up Delhi Courts Scraper...\")\n",
        "%pip install -q google-colab-selenium selenium beautifulsoup4 reportlab requests lxml PyPDF2\n",
        "\n",
        "print(\"✅ Setup complete!\")\n",
        "\n",
        "# ─── STEP 2: IMPORTS ───\n",
        "import os, time, json, warnings, re\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Dict, List, Optional\n",
        "from IPython.display import display, FileLink, HTML\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from reportlab.lib.pagesizes import A4\n",
        "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer\n",
        "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
        "from reportlab.lib import colors\n",
        "from reportlab.lib.units import inch\n",
        "import google_colab_selenium as gs  # Handles browser + driver magic\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✅ Libraries imported!\")\n",
        "\n",
        "# ─── STEP 3: DELHI COURTS SCRAPER (gs.Chrome for Reliability) ───\n",
        "class DelhiCourtsScraper:\n",
        "    \"\"\"Scraper for Delhi District Courts\"\"\"\n",
        "\n",
        "    # Delhi court complexes with their URLs (unchanged)\n",
        "    COURT_COMPLEXES = {\n",
        "        \"Central Delhi\": {\n",
        "            \"url\": \"https://delhicourts.nic.in/central-district\",\n",
        "            \"cause_list\": \"https://delhicourts.nic.in/writereaddata/Upload/CauseList/Central/\"\n",
        "        },\n",
        "        \"East Delhi\": {\n",
        "            \"url\": \"https://delhicourts.nic.in/east-district\",\n",
        "            \"cause_list\": \"https://delhicourts.nic.in/writereaddata/Upload/CauseList/East/\"\n",
        "        },\n",
        "        \"New Delhi\": {\n",
        "            \"url\": \"https://delhicourts.nic.in/newdelhi-district\",\n",
        "            \"cause_list\": \"https://delhicourts.nic.in/writereaddata/Upload/CauseList/NewDelhi/\"\n",
        "        },\n",
        "        \"North Delhi\": {\n",
        "            \"url\": \"https://delhicourts.nic.in/north-district\",\n",
        "            \"cause_list\": \"https://delhicourts.nic.in/writereaddata/Upload/CauseList/North/\"\n",
        "        },\n",
        "        \"North East Delhi\": {\n",
        "            \"url\": \"https://delhicourts.nic.in/northeast-district\",\n",
        "            \"cause_list\": \"https://delhicourts.nic.in/writereaddata/Upload/CauseList/NorthEast/\"\n",
        "        },\n",
        "        \"North West Delhi\": {\n",
        "            \"url\": \"https://delhicourts.nic.in/northwest-district\",\n",
        "            \"cause_list\": \"https://delhicourts.nic.in/writereaddata/Upload/CauseList/NorthWest/\"\n",
        "        },\n",
        "        \"Shahdara Delhi\": {\n",
        "            \"url\": \"https://delhicourts.nic.in/shahdara-district\",\n",
        "            \"cause_list\": \"https://delhicourts.nic.in/writereaddata/Upload/CauseList/Shahdara/\"\n",
        "        },\n",
        "        \"South Delhi\": {\n",
        "            \"url\": \"https://delhicourts.nic.in/south-district\",\n",
        "            \"cause_list\": \"https://delhicourts.nic.in/writereaddata/Upload/CauseList/South/\"\n",
        "        },\n",
        "        \"South East Delhi\": {\n",
        "            \"url\": \"https://delhicourts.nic.in/southeast-district\",\n",
        "            \"cause_list\": \"https://delhicourts.nic.in/writereaddata/Upload/CauseList/SouthEast/\"\n",
        "        },\n",
        "        \"South West Delhi\": {\n",
        "            \"url\": \"https://delhicourts.nic.in/southwest-district\",\n",
        "            \"cause_list\": \"https://delhicourts.nic.in/writereaddata/Upload/CauseList/SouthWest/\"\n",
        "        },\n",
        "        \"West Delhi\": {\n",
        "            \"url\": \"https://delhicourts.nic.in/west-district\",\n",
        "            \"cause_list\": \"https://delhicourts.nic.in/writereaddata/Upload/CauseList/West/\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "    def __init__(self):\n",
        "        self.dir = \"/content/delhi_courts_output\"\n",
        "        os.makedirs(f\"{self.dir}/pdfs\", exist_ok=True)\n",
        "        os.makedirs(f\"{self.dir}/json\", exist_ok=True)\n",
        "\n",
        "        print(\"🌐 Starting browser...\")\n",
        "        # Magic: gs.Chrome() auto-installs matching driver + sets Colab-safe options\n",
        "        self.driver = gs.Chrome()\n",
        "        self.wait = WebDriverWait(self.driver, 20)\n",
        "        print(\"✅ Browser ready!\")\n",
        "\n",
        "    def get_complexes(self):\n",
        "        \"\"\"Get list of court complexes\"\"\"\n",
        "        return list(self.COURT_COMPLEXES.keys())\n",
        "\n",
        "    def scrape_cause_list_page(self, complex_name, date_str):\n",
        "        \"\"\"Scrape cause list from court website\"\"\"\n",
        "        try:\n",
        "            if complex_name not in self.COURT_COMPLEXES:\n",
        "                print(f\"❌ Unknown complex: {complex_name}\")\n",
        "                return []\n",
        "\n",
        "            complex_url = self.COURT_COMPLEXES[complex_name][\"url\"]\n",
        "            print(f\"📍 Opening {complex_name} court website...\")\n",
        "\n",
        "            self.driver.get(complex_url)\n",
        "            time.sleep(3)\n",
        "\n",
        "            # Look for cause list links\n",
        "            print(\"🔍 Searching for cause list links...\")\n",
        "\n",
        "            # Try to find cause list section\n",
        "            links = self.driver.find_elements(By.TAG_NAME, \"a\")\n",
        "            cause_list_links = []\n",
        "\n",
        "            for link in links:\n",
        "                href = link.get_attribute(\"href\")\n",
        "                text = link.text.lower()\n",
        "                if href and (\"cause\" in text or \"daily\" in text or \".pdf\" in href.lower()):\n",
        "                    cause_list_links.append({\n",
        "                        \"text\": link.text,\n",
        "                        \"url\": href\n",
        "                    })\n",
        "\n",
        "            print(f\"✅ Found {len(cause_list_links)} potential cause list links\")\n",
        "            return cause_list_links\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error: {str(e)[:200]}\")\n",
        "            return []\n",
        "\n",
        "    def download_pdf_from_url(self, url, filename):\n",
        "        \"\"\"Download PDF from URL\"\"\"\n",
        "        try:\n",
        "            print(f\"📥 Downloading: {filename}\")\n",
        "            response = requests.get(url, timeout=30)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            filepath = f\"{self.dir}/pdfs/{filename}\"\n",
        "            with open(filepath, 'wb') as f:\n",
        "                f.write(response.content)\n",
        "\n",
        "            print(f\"✅ Saved: {filename}\")\n",
        "            return filepath\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Download failed: {str(e)[:100]}\")\n",
        "            return None\n",
        "\n",
        "    def scrape_by_date_method(self, complex_name, date_str):\n",
        "        \"\"\"Alternative method: Try to construct direct PDF URLs\"\"\"\n",
        "        results = []\n",
        "\n",
        "        try:\n",
        "            # Parse date\n",
        "            dt = datetime.strptime(date_str, \"%d-%m-%Y\")\n",
        "\n",
        "            # Common URL patterns for Delhi courts\n",
        "            patterns = [\n",
        "                f\"{dt.strftime('%d%m%Y')}.pdf\",\n",
        "                f\"{dt.strftime('%d-%m-%Y')}.pdf\",\n",
        "                f\"causelist_{dt.strftime('%d%m%Y')}.pdf\",\n",
        "                f\"CauseList_{dt.strftime('%d%m%Y')}.pdf\",\n",
        "                f\"{dt.strftime('%d.%m.%Y')}.pdf\",\n",
        "            ]\n",
        "\n",
        "            base_url = self.COURT_COMPLEXES[complex_name][\"cause_list\"]\n",
        "\n",
        "            for pattern in patterns:\n",
        "                url = base_url + pattern\n",
        "                print(f\"🔍 Trying: {url}\")\n",
        "\n",
        "                try:\n",
        "                    response = requests.head(url, timeout=10)\n",
        "                    if response.status_code == 200:\n",
        "                        print(f\"✅ Found PDF at: {url}\")\n",
        "                        filename = f\"{complex_name.replace(' ', '_')}_{date_str.replace('-', '')}.pdf\"\n",
        "                        filepath = self.download_pdf_from_url(url, filename)\n",
        "                        if filepath:\n",
        "                            results.append({\n",
        "                                \"complex\": complex_name,\n",
        "                                \"date\": date_str,\n",
        "                                \"url\": url,\n",
        "                                \"file\": filepath,\n",
        "                                \"success\": True\n",
        "                            })\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error in date method: {str(e)[:100]}\")\n",
        "            return []\n",
        "\n",
        "    def scrape_interactive_portal(self, complex_name, date_str):\n",
        "        \"\"\"Scrape using interactive portal\"\"\"\n",
        "        try:\n",
        "            # Navigate to the main cause list page\n",
        "            base_url = \"https://delhicourts.nic.in/\"\n",
        "            print(f\"📍 Navigating to {base_url}\")\n",
        "\n",
        "            self.driver.get(base_url)\n",
        "            time.sleep(3)\n",
        "\n",
        "            # Look for \"Cause List\" or \"Daily Board\" link\n",
        "            try:\n",
        "                cause_list_link = self.driver.find_element(\n",
        "                    By.XPATH,\n",
        "                    \"//a[contains(text(), 'Cause List') or contains(text(), 'Daily Board')]\"\n",
        "                )\n",
        "                cause_list_link.click()\n",
        "                time.sleep(3)\n",
        "            except:\n",
        "                print(\"⚠️ Could not find cause list link\")\n",
        "\n",
        "            # Try to find district selection\n",
        "            try:\n",
        "                district_select = Select(self.driver.find_element(By.ID, \"district\"))\n",
        "                district_select.select_by_visible_text(complex_name)\n",
        "                time.sleep(2)\n",
        "            except:\n",
        "                print(\"⚠️ Could not select district\")\n",
        "\n",
        "            # Try to enter date\n",
        "            try:\n",
        "                date_input = self.driver.find_element(By.ID, \"date\")\n",
        "                date_input.clear()\n",
        "                date_input.send_keys(date_str)\n",
        "                time.sleep(1)\n",
        "            except:\n",
        "                print(\"⚠️ Could not enter date\")\n",
        "\n",
        "            # Click submit\n",
        "            try:\n",
        "                submit_btn = self.driver.find_element(\n",
        "                    By.XPATH,\n",
        "                    \"//button[contains(text(), 'Search')] | //input[@type='submit']\"\n",
        "                )\n",
        "                submit_btn.click()\n",
        "                time.sleep(4)\n",
        "            except:\n",
        "                print(\"⚠️ Could not click submit\")\n",
        "\n",
        "            # Look for download links\n",
        "            pdf_links = self.driver.find_elements(By.XPATH, \"//a[contains(@href, '.pdf')]\")\n",
        "\n",
        "            results = []\n",
        "            for i, link in enumerate(pdf_links, 1):\n",
        "                url = link.get_attribute(\"href\")\n",
        "                text = link.text or f\"Cause_List_{i}\"\n",
        "\n",
        "                filename = f\"{complex_name.replace(' ', '_')}_{text.replace(' ', '_')}_{date_str.replace('-', '')}.pdf\"\n",
        "                filepath = self.download_pdf_from_url(url, filename)\n",
        "\n",
        "                if filepath:\n",
        "                    results.append({\n",
        "                        \"complex\": complex_name,\n",
        "                        \"date\": date_str,\n",
        "                        \"name\": text,\n",
        "                        \"file\": filepath,\n",
        "                        \"success\": True\n",
        "                    })\n",
        "\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Interactive portal error: {str(e)[:200]}\")\n",
        "            return []\n",
        "\n",
        "    def download_all_for_date(self, date_str):\n",
        "        \"\"\"Download cause lists from all complexes for a date\"\"\"\n",
        "        all_results = []\n",
        "        complexes = self.get_complexes()\n",
        "\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"Downloading cause lists for {date_str} from ALL Delhi courts\")\n",
        "        print(f\"{'='*70}\\n\")\n",
        "\n",
        "        for i, complex_name in enumerate(complexes, 1):\n",
        "            print(f\"\\n[{i}/{len(complexes)}] {complex_name}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "            # Try multiple methods\n",
        "            results = []\n",
        "\n",
        "            # Method 1: Direct PDF URL patterns\n",
        "            results.extend(self.scrape_by_date_method(complex_name, date_str))\n",
        "\n",
        "            # Method 2: Scrape court page\n",
        "            if not results:\n",
        "                links = self.scrape_cause_list_page(complex_name, date_str)\n",
        "                for link in links:\n",
        "                    if \".pdf\" in link[\"url\"].lower():\n",
        "                        filename = f\"{complex_name.replace(' ', '_')}_{link['text'].replace(' ', '_')}.pdf\"\n",
        "                        filepath = self.download_pdf_from_url(link[\"url\"], filename)\n",
        "                        if filepath:\n",
        "                            results.append({\n",
        "                                \"complex\": complex_name,\n",
        "                                \"file\": filepath,\n",
        "                                \"success\": True\n",
        "                            })\n",
        "\n",
        "            if results:\n",
        "                print(f\"✅ Downloaded {len(results)} files for {complex_name}\")\n",
        "            else:\n",
        "                print(f\"⚠️ No cause lists found for {complex_name}\")\n",
        "\n",
        "            all_results.extend(results)\n",
        "            time.sleep(2)  # Be respectful to the server\n",
        "\n",
        "        return all_results\n",
        "\n",
        "    def download_for_complex(self, complex_name, date_str):\n",
        "        \"\"\"Download cause list for specific complex\"\"\"\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"Downloading: {complex_name} - {date_str}\")\n",
        "        print(f\"{'='*70}\\n\")\n",
        "\n",
        "        results = []\n",
        "\n",
        "        # Method 1: Direct URL\n",
        "        results.extend(self.scrape_by_date_method(complex_name, date_str))\n",
        "\n",
        "        # Method 2: Scrape page\n",
        "        if not results:\n",
        "            results.extend(self.scrape_interactive_portal(complex_name, date_str))\n",
        "\n",
        "        # Method 3: Page links\n",
        "        if not results:\n",
        "            links = self.scrape_cause_list_page(complex_name, date_str)\n",
        "            for link in links:\n",
        "                if \".pdf\" in link[\"url\"].lower():\n",
        "                    filename = f\"{complex_name.replace(' ', '_')}_{date_str.replace('-', '')}.pdf\"\n",
        "                    filepath = self.download_pdf_from_url(link[\"url\"], filename)\n",
        "                    if filepath:\n",
        "                        results.append({\n",
        "                            \"complex\": complex_name,\n",
        "                            \"date\": date_str,\n",
        "                            \"file\": filepath,\n",
        "                            \"success\": True\n",
        "                        })\n",
        "\n",
        "        return results\n",
        "\n",
        "print(\"✅ Delhi Courts Scraper ready!\")\n",
        "\n",
        "# ─── STEP 4: INTERACTIVE FUNCTION ───\n",
        "def run_delhi_scraper():\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"  Delhi District Courts - Cause List Scraper\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    scraper = DelhiCourtsScraper()\n",
        "\n",
        "    try:\n",
        "        complexes = scraper.get_complexes()\n",
        "\n",
        "        print(\"🏛️ Available Delhi District Courts:\\n\")\n",
        "        for i, comp in enumerate(complexes, 1):\n",
        "            print(f\"  {i}. {comp}\")\n",
        "        print(f\"  {len(complexes) + 1}. ALL Courts (Download from all)\")\n",
        "\n",
        "        choice = input(f\"\\n👉 Select court (1-{len(complexes) + 1}): \").strip()\n",
        "\n",
        "        # Date input\n",
        "        date_input = input(f\"\\n📅 Enter date (DD-MM-YYYY) [Press Enter for today]: \").strip()\n",
        "        if not date_input:\n",
        "            date_input = datetime.now().strftime(\"%d-%m-%Y\")\n",
        "        print(f\"✅ Date: {date_input}\\n\")\n",
        "\n",
        "        choice_idx = int(choice) - 1\n",
        "\n",
        "        if choice_idx == len(complexes):\n",
        "            # Download from all courts\n",
        "            print(\"📥 Downloading from ALL Delhi District Courts...\\n\")\n",
        "            results = scraper.download_all_for_date(date_input)\n",
        "        else:\n",
        "            # Download from specific court\n",
        "            if 0 <= choice_idx < len(complexes):\n",
        "                selected_complex = complexes[choice_idx]\n",
        "                results = scraper.download_for_complex(selected_complex, date_input)\n",
        "            else:\n",
        "                print(\"❌ Invalid selection\")\n",
        "                return\n",
        "\n",
        "        # Display results\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        successful = [r for r in results if r.get(\"success\")]\n",
        "        print(f\"✅ Download Complete! Got {len(successful)} files\")\n",
        "        print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "        if successful:\n",
        "            print(\"📄 Downloaded Files:\\n\")\n",
        "            for result in successful:\n",
        "                print(f\"  • {result.get('complex', 'Unknown Court')}\")\n",
        "                if result.get('file'):\n",
        "                    print(f\"    {os.path.basename(result['file'])}\")\n",
        "                    display(FileLink(result['file']))\n",
        "                print()\n",
        "        else:\n",
        "            print(\"⚠️ No cause lists were downloaded.\")\n",
        "            print(\"\\nPossible reasons:\")\n",
        "            print(\"  • Cause lists not yet published for this date (try 16-10-2025)\")\n",
        "            print(\"  • Court website structure has changed\")\n",
        "            print(\"  • Internet connectivity issues\")\n",
        "            print(\"\\nTry:\")\n",
        "            print(\"  • A different date (yesterday)\")\n",
        "            print(\"  • Checking the court website manually\")\n",
        "\n",
        "        # Save summary\n",
        "        summary_file = f\"{scraper.dir}/json/summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "        with open(summary_file, 'w') as f:\n",
        "            json.dump(results, f, indent=2)\n",
        "        print(f\"\\n💾 Summary saved: {os.path.basename(summary_file)}\")\n",
        "        display(FileLink(summary_file))\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n\\n⚠️ Cancelled by user\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "    finally:\n",
        "        try:\n",
        "            scraper.driver.quit()\n",
        "            print(\"\\n✅ Browser closed\")\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "# ─── STEP 5: QUICK DOWNLOAD FUNCTION ───\n",
        "def quick_download_delhi(date=None, court=\"all\"):\n",
        "    \"\"\"Quick download function for advanced users\"\"\"\n",
        "    if date is None:\n",
        "        date = datetime.now().strftime(\"%d-%m-%Y\")\n",
        "\n",
        "    scraper = DelhiCourtsScraper()\n",
        "\n",
        "    try:\n",
        "        if court == \"all\":\n",
        "            results = scraper.download_all_for_date(date)\n",
        "        else:\n",
        "            results = scraper.download_for_complex(court, date)\n",
        "\n",
        "        successful = [r for r in results if r.get(\"success\")]\n",
        "        print(f\"\\n✅ Downloaded {len(successful)} files\")\n",
        "\n",
        "        for result in successful:\n",
        "            if result.get('file'):\n",
        "                display(FileLink(result['file']))\n",
        "\n",
        "        return results\n",
        "    finally:\n",
        "        scraper.driver.quit()\n",
        "\n",
        "print(\"✅ All functions ready!\")\n",
        "\n",
        "# ─── STEP 6: RUN THE SCRAPER ───\n",
        "print(\"\\n🚀 Starting Delhi Courts Scraper...\\n\")\n",
        "run_delhi_scraper()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✅ Process Complete!\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nFiles saved to: {os.path.abspath('/content/delhi_courts_output')}\")\n",
        "print(\"\\nTo run again, execute: run_delhi_scraper()\")\n",
        "print(\"For quick download: quick_download_delhi(date='16-10-2025', court='New Delhi')\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests beautifulsoup4 tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfN952XvTWPO",
        "outputId": "c074aff7-cccb-4461-e1d5-c32940e6ba34"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n"
          ]
        }
      ]
    }
  ]
}